{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file\n",
    "\n",
    "with open('dataset/input.txt','r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "# Length of text\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the text\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters: 65\n",
      "Characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# Check unique characters \n",
    "chars = sorted(list(set(text)))\n",
    "print(f'number of unique characters: {len(chars)}')\n",
    "print(f'Characters: {\"\".join(chars)}')\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43, 2]\n",
      "MUnLK ew\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]  # Function takes a string and retuns encoded integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # Function takes a list of integers and returns a decoded string\n",
    "\n",
    "print(encode(\"hello there!\"))\n",
    "print(decode([25,33,52,24,23,1,43,61]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data, val_data = data[:n], data[n:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train Block size/ Context length\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is 47\n",
      "when input is tensor([18, 47]) the target is 56\n",
      "when input is tensor([18, 47, 56]) the target is 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "# How context works with example\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "_______________\n",
      "when context is [24] the target is 43\n",
      "when context is [24, 43] the target is 58\n",
      "when context is [24, 43, 58] the target is 5\n",
      "when context is [24, 43, 58, 5] the target is 57\n",
      "when context is [24, 43, 58, 5, 57] the target is 1\n",
      "when context is [24, 43, 58, 5, 57, 1] the target is 46\n",
      "when context is [24, 43, 58, 5, 57, 1, 46] the target is 43\n",
      "when context is [24, 43, 58, 5, 57, 1, 46, 43] the target is 39\n",
      "when context is [44] the target is 53\n",
      "when context is [44, 53] the target is 56\n",
      "when context is [44, 53, 56] the target is 1\n",
      "when context is [44, 53, 56, 1] the target is 58\n",
      "when context is [44, 53, 56, 1, 58] the target is 46\n",
      "when context is [44, 53, 56, 1, 58, 46] the target is 39\n",
      "when context is [44, 53, 56, 1, 58, 46, 39] the target is 58\n",
      "when context is [44, 53, 56, 1, 58, 46, 39, 58] the target is 1\n",
      "when context is [52] the target is 58\n",
      "when context is [52, 58] the target is 1\n",
      "when context is [52, 58, 1] the target is 58\n",
      "when context is [52, 58, 1, 58] the target is 46\n",
      "when context is [52, 58, 1, 58, 46] the target is 39\n",
      "when context is [52, 58, 1, 58, 46, 39] the target is 58\n",
      "when context is [52, 58, 1, 58, 46, 39, 58] the target is 1\n",
      "when context is [52, 58, 1, 58, 46, 39, 58, 1] the target is 46\n",
      "when context is [25] the target is 17\n",
      "when context is [25, 17] the target is 27\n",
      "when context is [25, 17, 27] the target is 10\n",
      "when context is [25, 17, 27, 10] the target is 0\n",
      "when context is [25, 17, 27, 10, 0] the target is 21\n",
      "when context is [25, 17, 27, 10, 0, 21] the target is 1\n",
      "when context is [25, 17, 27, 10, 0, 21, 1] the target is 54\n",
      "when context is [25, 17, 27, 10, 0, 21, 1, 54] the target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 \n",
    "block_size = 8 \n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of input data x and target y \n",
    "    data = train_data if split == 'train' else val_data \n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y \n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "print('inputs: ')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print('targets: ')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('_______________')\n",
    "\n",
    "\n",
    "\n",
    "for b in range (batch_size):    # batch dim\n",
    "    for t in range(block_size): # time dim\n",
    "        context = xb[b, :t+1]\n",
    "        target  = yb[b,t]\n",
    "        print(f'when context is {context.tolist()} the target is {target}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(5.0364, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F  \n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        logits = self.token_embedding_table(idx) # Batch, Time(block size), Channel(vocab size) = BTC\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            # print(B, T, C)\n",
    "\n",
    "            logits = logits.view(B*T , C)\n",
    "            targets = targets.view(B*T)\n",
    "            \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits , loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get prediction\n",
    "            logits, loss = self(idx)\n",
    "            #focus only on the last time step\n",
    "            logits = logits[:,-1,:] #becomes (B,C)\n",
    "            #apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) # B,C\n",
    "            # Sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
    "            #append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next),dim=1) #(B,T+1)\n",
    "        return idx \n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lfJeukRuaRJKXAYtXzfJ:HEPiu--sDioi;ILCo3pHNTmDwJsfheKRxZCFs\n",
      "lZJ XQc?:s:HEzEnXalEPklcPU cL'DpdLCafBheH\n"
     ]
    }
   ],
   "source": [
    "# Check how the model outputs garbage before training\n",
    "\n",
    "idx0 = torch.zeros((1,1),dtype=torch.long)\n",
    "print(decode(m.generate(idx0, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\tLoss 4.6477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_21408\\3608761181.py:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if step%100 is 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100\tLoss 4.5645\n",
      "Step 200\tLoss 4.4897\n",
      "Step 300\tLoss 4.3434\n",
      "Step 400\tLoss 4.2009\n",
      "Step 500\tLoss 4.1076\n",
      "Step 600\tLoss 3.9540\n",
      "Step 700\tLoss 3.9091\n",
      "Step 800\tLoss 3.8039\n",
      "Step 900\tLoss 3.7947\n",
      "Step 1000\tLoss 3.6683\n",
      "Step 1100\tLoss 3.6054\n",
      "Step 1200\tLoss 3.5995\n",
      "Step 1300\tLoss 3.5802\n",
      "Step 1400\tLoss 3.4669\n",
      "Step 1500\tLoss 3.3458\n",
      "Step 1600\tLoss 3.2836\n",
      "Step 1700\tLoss 3.1671\n",
      "Step 1800\tLoss 3.1332\n",
      "Step 1900\tLoss 3.1885\n",
      "Step 2000\tLoss 3.3209\n",
      "Step 2100\tLoss 3.0852\n",
      "Step 2200\tLoss 3.0418\n",
      "Step 2300\tLoss 3.0337\n",
      "Step 2400\tLoss 2.9010\n",
      "Step 2500\tLoss 2.9626\n",
      "Step 2600\tLoss 2.7994\n",
      "Step 2700\tLoss 2.9445\n",
      "Step 2800\tLoss 2.9192\n",
      "Step 2900\tLoss 2.7770\n",
      "Step 3000\tLoss 2.8779\n",
      "Step 3100\tLoss 2.7572\n",
      "Step 3200\tLoss 2.6434\n",
      "Step 3300\tLoss 2.6713\n",
      "Step 3400\tLoss 2.7567\n",
      "Step 3500\tLoss 2.6116\n",
      "Step 3600\tLoss 2.7023\n",
      "Step 3700\tLoss 2.6181\n",
      "Step 3800\tLoss 2.6877\n",
      "Step 3900\tLoss 2.5604\n",
      "Step 4000\tLoss 2.6919\n",
      "Step 4100\tLoss 2.7078\n",
      "Step 4200\tLoss 2.6816\n",
      "Step 4300\tLoss 2.6944\n",
      "Step 4400\tLoss 2.5496\n",
      "Step 4500\tLoss 2.6288\n",
      "Step 4600\tLoss 2.5659\n",
      "Step 4700\tLoss 2.6009\n",
      "Step 4800\tLoss 2.5666\n",
      "Step 4900\tLoss 2.6167\n",
      "Step 5000\tLoss 2.4803\n",
      "Step 5100\tLoss 2.4859\n",
      "Step 5200\tLoss 2.6072\n",
      "Step 5300\tLoss 2.5963\n",
      "Step 5400\tLoss 2.5240\n",
      "Step 5500\tLoss 2.5048\n",
      "Step 5600\tLoss 2.5231\n",
      "Step 5700\tLoss 2.4759\n",
      "Step 5800\tLoss 2.5204\n",
      "Step 5900\tLoss 2.5198\n",
      "Step 6000\tLoss 2.5016\n",
      "Step 6100\tLoss 2.4886\n",
      "Step 6200\tLoss 2.5871\n",
      "Step 6300\tLoss 2.4895\n",
      "Step 6400\tLoss 2.5062\n",
      "Step 6500\tLoss 2.3962\n",
      "Step 6600\tLoss 2.5385\n",
      "Step 6700\tLoss 2.4557\n",
      "Step 6800\tLoss 2.6058\n",
      "Step 6900\tLoss 2.4277\n",
      "Step 7000\tLoss 2.5092\n",
      "Step 7100\tLoss 2.4265\n",
      "Step 7200\tLoss 2.4667\n",
      "Step 7300\tLoss 2.5388\n",
      "Step 7400\tLoss 2.4872\n",
      "Step 7500\tLoss 2.6031\n",
      "Step 7600\tLoss 2.4124\n",
      "Step 7700\tLoss 2.4134\n",
      "Step 7800\tLoss 2.5180\n",
      "Step 7900\tLoss 2.4994\n",
      "Step 8000\tLoss 2.4072\n",
      "Step 8100\tLoss 2.6155\n",
      "Step 8200\tLoss 2.4791\n",
      "Step 8300\tLoss 2.5104\n",
      "Step 8400\tLoss 2.4277\n",
      "Step 8500\tLoss 2.3796\n",
      "Step 8600\tLoss 2.5436\n",
      "Step 8700\tLoss 2.4105\n",
      "Step 8800\tLoss 2.4113\n",
      "Step 8900\tLoss 2.4769\n",
      "Step 9000\tLoss 2.4279\n",
      "Step 9100\tLoss 2.5649\n",
      "Step 9200\tLoss 2.5715\n",
      "Step 9300\tLoss 2.5192\n",
      "Step 9400\tLoss 2.3286\n",
      "Step 9500\tLoss 2.4110\n",
      "Step 9600\tLoss 2.5081\n",
      "Step 9700\tLoss 2.4637\n",
      "Step 9800\tLoss 2.4191\n",
      "Step 9900\tLoss 2.5331\n",
      "----done----\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "learning_steps = 10000\n",
    "for step in range(learning_steps):\n",
    "    #sample the batch\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    #evaluate loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step%100 is 0:\n",
    "        print(\"Step %d\\tLoss %.4f\" % (step, loss))\n",
    "    \n",
    "print('----done----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M:\n",
      "IUSh t,\n",
      "F th he d ke alved.\n",
      "Thupld, cipbll t\n",
      "I: ir w, l me sie hend lor ito'l an e\n",
      "\n",
      "I:\n",
      "Gochosen ea ar btamandd halind wast, plt t wadyotl\n",
      "I bel qunganonoth he m he de avellis knt, tond soran:\n",
      "\n",
      "WI he toust are bot g e n t s d je hid t his IAces I my ig t\n",
      "Ril'swoll e pupat inouleacends-athiqu heamer te\n",
      "Wht s\n",
      "\n",
      "MI wect!-lltherotheve t fe;\n",
      "WAnd pporury t s ld tathat, ir V\n",
      "IO thesecin teot tit ado ilorer.\n",
      "Ply, d'stacoes, ld omat mealellly yererer EMEvesas ie IZEd pave mautoofareanerllleyomerer but?\n",
      "The t,\n",
      "Ith'dwitile w? beren to'd ff a atrts brey s\n",
      "\n",
      "ESesenther:\n",
      "Ithon f at pare ismamy an flictong m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mameld h che IN: an y is aslo'daDut, t thethiceve fur t anowik\n",
      "Wirghe f bot d at'prd\n",
      "Anoper sof usy be, d s me cks bity.\n",
      "Cis:\n",
      "INILou f lendys.\n",
      "Y anditont avenghe m, gs gl tis y.\n",
      "Wie gh-mmo hizy s me f lourachigethuiclotif qDWeZPld:\n",
      "LOubour Witamul we thiech l lisowarrew bland cedanidate, fafive withe thiulsosthis thatwancaurind th'gonimake\n",
      "\n",
      "S oveprene?\n",
      "Hear oumnanoupamak in:\n",
      "\n",
      "The!\n",
      "The f d sd\n"
     ]
    }
   ],
   "source": [
    "# Check how the model outputs garbage before training\n",
    "\n",
    "idx0 = torch.zeros((1,1),dtype=torch.long)\n",
    "print(decode(m.generate(idx0, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Matrix\n",
    "### Easing calculations using matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [12., 18.],\n",
      "        [14.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "G = torch.randint(low=1,high=20, size=(3,2), dtype=torch.float32)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sum_mat = torch.ones((3,3), dtype=torch.float32)\n",
    "print(sum_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 21.],\n",
      "        [27., 21.],\n",
      "        [27., 21.]])\n"
     ]
    }
   ],
   "source": [
    "# To sum the columns\n",
    "\n",
    "print(sum_mat @ G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[ 1.,  2.],\n",
      "        [13., 20.],\n",
      "        [27., 21.]])\n"
     ]
    }
   ],
   "source": [
    "# To do cumilitive sum along columns\n",
    "\n",
    "cumsum = torch.tril(sum_mat)\n",
    "print(cumsum)\n",
    "print(cumsum @ G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "# To do average along the rows\n",
    "\n",
    "mean_mat = torch.tril(torch.ones((3,3), dtype=torch.float32)) \n",
    "mean_mat = mean_mat / mean_mat.sum(1, keepdim=True)\n",
    "\n",
    "print(mean_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  2.0000],\n",
       "        [ 6.5000, 10.0000],\n",
       "        [ 9.0000,  7.0000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO get the mean of a given 3x3 matrix\n",
    "mean_mat @ G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Higher dim example \n",
    "B, T, C = 4,8,2\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want x[b,t] = mean {i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b,t] = torch.mean(xprev,0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "wei "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow2 = wei @ x # (T,T) @ (B,T,C) ---> (B,T,T) @ (B, T, C) =---> (B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare if they are equal \n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 3 \n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "\n",
    "print(wei)\n",
    "\n",
    "xbow3 = wei @ x \n",
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=32, out_features=16, bias=False)\n",
      "torch.Size([4, 8, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Implement a single head of self att\n",
    "head_size = 16 \n",
    "key = nn.Linear(C,head_size,bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "print(key)\n",
    "\n",
    "k = key(x)    # (B,T,16)\n",
    "q = query(x)  # (B,T,16)\n",
    "v = value(x)\n",
    "\n",
    "print(k.shape)\n",
    "\n",
    "wei = q @ k.transpose(-2,-1) # (B,T,16) @ (B,16,T) ---> (B,T,T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "\n",
    "\n",
    "out = wei @ v \n",
    "# out = wei @ x\n",
    "\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing fuctionality of nn.Linear in torch for myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 7])\n",
      "torch.Size([2, 3, 11])\n"
     ]
    }
   ],
   "source": [
    "ex1 = torch.randn(2,3,7)\n",
    "print(ex1.shape)\n",
    "lex = nn.Linear(7, 11, bias=False)\n",
    "\n",
    "j = lex(ex1)\n",
    "\n",
    "print(j.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why divide by the sqrt(head_size) for the attention calculation -> TO normalize the variance <br>\n",
    "\n",
    "Otherwise wei will start to converge towards one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = torch.randn(B,T,head_size)\n",
    "q1 = torch.randn(B,T,head_size)\n",
    "wei1 = q1 @ k1.transpose(-2,-1) \n",
    "wei_norm = wei * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9859)\n",
      "tensor(1.0134)\n",
      "tensor(15.6108)\n",
      "tensor(0.0030, grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(k1.var())\n",
    "print(q1.var())\n",
    "print(wei1.var())\n",
    "print(wei_norm.var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
